{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded URLs from c:\\Users\\Francesco\\Fbref-scraping\\Team-Page-urls\\urls.xlsx\n",
      "Normalized team name: Gwangju\n",
      "Found matching URL for Gwangju: https://fbref.com/en/squads/ae306ede/Gwangju-FC-Stats\n",
      "Scraping data from: https://fbref.com/en/squads/ae306ede/Gwangju-FC-Stats\n",
      "Data saved to c:\\Users\\Francesco\\Fbref-scraping\\Fixtures\\Gwangju_matches_2024.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Add team input from user\n",
    "\n",
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    driver = init_webdriver()\n",
    "    league_url = \"https://fbref.com/en/comps/55/K-League-1-Stats\"\n",
    "    \n",
    "    try:\n",
    "        # if urls have not been fetched, scrape and save them\n",
    "        if not check_url_file_exists():\n",
    "            league_html = get_page_content(driver,league_url)\n",
    "            team_urls = extract_league_teams(league_html)\n",
    "            url_df = pd.DataFrame(team_urls, columns=[\"urls\"])\n",
    "            url_file = save_team_urls(url_df)\n",
    "        # Load the urls file\n",
    "        url_df = load_team_urls()\n",
    "        team_input = input(\"Enter the team you want to scrape data for: \")\n",
    "        team = normalize_team_name(team_input)\n",
    "        print(f\"Normalized team name: {team}\")\n",
    "\n",
    "        # Search for the team in the 'urls' column of the DataFrame\n",
    "        matching_url = None\n",
    "        for url in url_df[\"urls\"]:\n",
    "            if team in url:  # Check if the normalized team name is part of the URL\n",
    "                matching_url = url\n",
    "                break\n",
    "        \n",
    "        # Check if we found a matching URL, if we do execute the scraping and save team fixture data in an Excel file\n",
    "        if matching_url:\n",
    "            print(f\"Found matching URL for {team}: {matching_url}\")\n",
    "            print(f\"Scraping data from: {matching_url}\")\n",
    "            table_name = \"matchlogs_for\"\n",
    "            html = get_page_content(driver, matching_url)\n",
    "            #table_exists = check_table(driver,table_name) for debugging purposes\n",
    "            headers, data = extract_table_data(html,table_name)\n",
    "            df = create_dataframe(headers, data)\n",
    "            filename = save_data(df,team)\n",
    "            print(f\"Data saved to {filename}\")\n",
    "        else:\n",
    "            print(f\"No matching team found for {team}.\")\n",
    "    finally:\n",
    "        driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload utils after changes\n",
    "# Useful in development\n",
    "\n",
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NBA_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
