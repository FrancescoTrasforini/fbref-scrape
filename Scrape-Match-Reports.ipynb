{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    #edge_options = Options()\n",
    "    driver = init_webdriver()\n",
    "\n",
    "    try:\n",
    "        # Get team name from user\n",
    "        team_input = input(\"Enter the team for which you want to retrieve the match reports: \")\n",
    "        team = normalize_team_name(team_input)\n",
    "        print(f\"Normalized team name: {team}\")\n",
    "        # Define the folder path and ensure the folder exists\n",
    "        folder_path = os.path.join(os.getcwd(), \"Fixtures\")\n",
    "        os.makedirs(folder_path, exist_ok=True)  # Create the folder if it doesn't exist\n",
    "        filename = os.path.join(folder_path, f\"{team}_matches_2024.xlsx\")\n",
    "\n",
    "        # Open Excel file and insert data in dataframe\n",
    "        df = pd.read_excel(filename)\n",
    "        # Load the matchlogs_for page and extract URLs\n",
    "        url_df = load_team_urls()\n",
    "        # Search for the team in the 'urls' column of the DataFrame\n",
    "        matching_url = None\n",
    "        for url in url_df[\"urls\"]:\n",
    "            if team in url:  # Check if the normalized team name is part of the URL\n",
    "                matching_url = url\n",
    "                break\n",
    "\n",
    "        # Check if we found a matching URL, if we do execute the scraping and save team fixture data in an Excel file\n",
    "        if matching_url:\n",
    "            print(f\"Found matching URL for {team}: {matching_url}\")\n",
    "            html = get_page_content(driver, matching_url)\n",
    "            match_report_urls = extract_match_report_urls(html)\n",
    "\n",
    "            # Update the main Excel file with URLs\n",
    "            update_match_report_urls(df, match_report_urls,team)\n",
    "\n",
    "            # Re-load the updated main Excel file with URLs\n",
    "            df = pd.read_excel(filename)\n",
    "\n",
    "            # Scrape and save each match report\n",
    "            scrape_and_save_reports(df,driver,team)\n",
    "        else:\n",
    "            print(f\"No matching team found for {team}.\")\n",
    "    finally:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload utils after changes\n",
    "# Useful in development\n",
    "\n",
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NBA_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
